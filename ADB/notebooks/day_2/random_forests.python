{"name":"ML 04 - Random Forests","dashboards":[],"guid":"8c1353e5-7cb2-4f0a-99d5-064d09fb4375","iPythonMetadata":null,"version":"NotebookV1","language":"python","inputWidgets":{},"origId":0,"commands":[{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"d0139148-7920-4528-8b34-c5ef8c3f0598","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"%md-sandbox\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px; height: 163px\">\n</div>","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"18505bdd-011f-44d5-b890-7af038a16404","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":1,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"72375279-fe40-444b-8eaf-750da4991fa0","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"%md\n##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Random Forests\n\nIn this lab, we are going to use the same dataset as in the last lab, but we are going to use a Random Forest instead of a single decision tree. \n\nWe will also use a parameter grid and cross-validation to perform hyperparameter tuning, as well as export our final model.\n\nThe code below is taken from the last lab to set up our data transformations.\n\n[Random Forest Scala Docs](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.regression.RandomForestRegressor)\n\n[Random Forest Python Docs](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.regression.RandomForestRegressor)\n\n[Spark ML Guide](https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-regression)","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"86715352-21ff-4550-837b-9e6ed29c8382","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":2,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"bf5d8edd-e00e-4ddc-bbcd-8449ce93ca71","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"%run \"../Includes/Classroom Setup\"","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"a0205330-4f20-44f7-9454-25292a182bc4","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":3,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"080c9b9f-f666-4067-aac5-9b7b9a3b6f16","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"# Code taken from previous lab\nfrom pyspark.ml.feature import VectorAssembler, VectorIndexer\n\ndf = (spark\n      .read\n      .option(\"header\", \"true\")\n      .option(\"inferSchema\", \"true\")\n      .csv(\"/databricks-datasets/bikeSharing/data-001/hour.csv\")\n      .drop(\"instant\", \"dteday\", \"casual\", \"registered\", \"holiday\", \"weekday\"))\n\ndf.cache()\n\ntrainDF, testDF = df.randomSplit([0.7, 0.3], seed=42)\n\nfeaturesCols = df.columns[:-1] # Removes \"cnt\"\n\nvectorAssembler = VectorAssembler(inputCols=featuresCols, outputCol=\"rawFeatures\")\n\nvectorIndexer = VectorIndexer(inputCol=\"rawFeatures\", outputCol=\"features\", maxCategories=4)","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"9d5a0e56-b56f-4a93-a28f-8eef98ab9bd7","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":4,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"c55ae57a-0490-4b74-8de9-f6b729822c66","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"%md\n##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Random Forests\n\nRandom forests and ensembles of decision trees are more powerful than a single decision tree alone. \n\nLet's take a look at all the hyperparameters we could change in [RandomForestRegressor](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.regression.RandomForestRegressor).","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"972160a2-ddbb-4a0c-aded-8c02c72d67bf","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":5,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"7b0be9ca-40d6-4495-a9cf-61ab696830c3","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"from pyspark.ml.regression import RandomForestRegressor\n\nrf = (RandomForestRegressor()\n      .setLabelCol(\"cnt\")\n      .setSeed(27))\n\nprint(rf.explainParams())","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"c262c0bd-4682-49b9-b3ec-a7542a3e2a86","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":6,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"49259135-7191-422c-b138-7c8d8ed62d94","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"%md\nTry changing the values of `numTrees` and `maxDepth` to any values you like\n\nHINT: Take a look at the docs","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"2abba06a-7750-4100-8c44-f737c6fd0948","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":7,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"71acada0-9ea7-4e9e-9c3e-00854e766e90","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"# TODO\nrf.<FILL_IN>","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"e4f9673a-4557-4b72-b837-0d062e659fff","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":8,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"c4ef2a34-4e74-47cf-aec0-7674882f1c2e","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"%md\n##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Pipeline\n\nNow that we have all of the feature transformations and estimators set up, let's put all of the stages together in the pipline.","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"2ccb2a31-bef4-42b1-b34a-124dc6d1c566","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":9,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"898b2880-f276-4928-a25c-a87f9f42c215","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"from pyspark.ml import Pipeline\n\npipeline = Pipeline(stages = [vectorAssembler, vectorIndexer, rf])\n\npipeline.getStages()","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"739ffe79-20da-4e9e-a27f-d0294d9519a6","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":10,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"7f71acb9-3c7a-4494-874e-892a1fed83a0","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"%md\nIf you want to look at what parameter each stage in the pipeline takes.","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"5f89b716-446e-4d9c-927d-1db31329bc41","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":11,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"4450727b-cc79-4b5d-ab30-9c6cec30baa6","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"pipeline.getStages()[0].extractParamMap()","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"b9246961-560e-488a-b061-22918a5ddb9e","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":12,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"76fc2b40-d8e3-48e5-9768-0bb5f7d5150a","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"%md\n##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) ParamGrid\n\nThere are a lot of hyperparamaters we could tune, and it would take a long time to manually configure.\n\nInstead of a manual (ad-hoc) approach, let's use Spark's [ParamGridBuilder](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.tuning.ParamGridBuilder) to find the optimal hyperparameters in a more systematic approach.\n\nIn this example notebook, we keep these trees shallow and use a relatively small number of trees. Let's define a grid of hyperparameters to test:\n  - maxDepth: max depth of each decision tree in the RF ensemble (Use the values `2, 5, 10`)\n  - numTrees: number of trees in each RF ensemble (Use the values `10, 50`)\n\n`addGrid()` accepts the name of the parameter (e.g. `rf.maxDepth`), and a list of the possible values (e.g. `[2, 5, 10]`).","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"6b984871-fc4f-41ac-962f-22535fc4fd8b","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":13,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"c890d616-d475-4323-989a-68dbaa225672","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"# TODO\nfrom pyspark.ml.tuning import ParamGridBuilder\n\nparamGrid = (ParamGridBuilder()\n            .addGrid(<FILL_IN>)\n            .addGrid(<FILL_IN>)\n            .build())","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"2d9510ec-8153-4140-8f85-a06c1f638713","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":14,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"bbe0c4bb-f9e6-4d36-adfb-bb250009691a","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"%md\n##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Cross Validation\n\nWe are also going to use 3-fold cross validation to identify the optimal maxDepth and numTrees combination.\n\n![crossValidation](https://files.training.databricks.com/images/301/CrossValidation.png)\n\nWith 3-fold cross-validation, we train on 2/3 of the data, and evaluate with the remaining (held-out) 1/3. We repeat this process 3 times, so each fold gets the chance to act as the validation set. We then average the results of the three rounds.","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"401aee7c-3879-4484-8249-c0c5daa80051","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":15,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"f3acb328-428a-46f7-a35b-ee5129aac4c8","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"%md\nWe pass in the `estimator` (pipeline), `evaluator`, and `estimatorParamMaps` to [CrossValidator](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.tuning.CrossValidator) so that it knows:\n- Which model to use\n- How to evaluate the model\n- What hyperparamters to set for the model\n\nWe can also set the number of folds we want to split our data into (3), as well as setting a seed so we all have the same split in the data.","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"339035ad-c44c-4279-93a4-f4f94870049c","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":16,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"4b4602e2-5883-4ba4-b93a-01818fd4eb67","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"from pyspark.ml.evaluation import RegressionEvaluator\n\nfrom pyspark.ml.tuning import CrossValidator\n\nevaluator = (RegressionEvaluator()\n             .setLabelCol(\"cnt\")\n             .setPredictionCol(\"prediction\"))\n\ncv = (CrossValidator()\n      .setEstimator(pipeline)\n      .setEvaluator(evaluator)\n      .setEstimatorParamMaps(paramGrid)\n      .setNumFolds(3)\n      .setSeed(27))","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"12d952a0-4ff1-412a-8fa6-0dcdcc2c5cfa","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":17,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"d685d8a4-fb12-4430-8c7d-57b173519728","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"cvModel = cv.fit(trainDF)","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"713de255-d1cc-435e-94ea-1d05b525bc63","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":18,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"db77b277-99bc-46e9-9694-763fa9b90452","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"%md\nLet's take a look at the model with the best hyperparameter configuration","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"fd48df71-e76a-4918-bb91-c254643961e7","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":19,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"085f9603-99f8-4c21-8f8b-f8dcef34db87","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"list(zip(cvModel.getEstimatorParamMaps(), cvModel.avgMetrics))","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"577ac158-3ec8-4b6f-b228-96eaa319e753","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":20,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"729d1040-6ac0-4ed7-bfee-9e77e67dabbd","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"%md\n##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Save Model\n\nLet's save our model by writing it out. \n\n**NOTE:** We cannot save a pipeline model with a cross-validation step in Python. Instead, we have to save the best pipeline model itself.\n\nAlso, there is no `overwrite` method. Our only alternative is to recursively delete the existing directory if we want to remove it.","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"e3eddd84-9a21-4b09-8dcb-62259f8848e0","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":21,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"905d9232-68a3-46dd-aa46-a02c2289db1a","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"path = \"/tmp/random_forest_pipeline\"\nmodelPath = userhome + path\ndbutils.fs.rm(modelPath, recurse=True)\n\ncvModel.bestModel.save(modelPath)","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"696d5537-5e7b-4555-957b-54fd0e294275","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":22,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"dd92c7dc-e9e6-41ab-99ac-a97d512d4e7a","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"%md\nLet's load the saved model back in.","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"35f95d77-7260-4da7-924a-c6a7f64eb98e","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":23,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"aa917567-0628-4711-b88a-e5445faabfed","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"from pyspark.ml.pipeline import PipelineModel\n\nsavedPipelineModel = PipelineModel.load(modelPath)","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"0d4e90a4-531a-421a-810c-f6bd76a9eed3","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":24,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"92563b26-bb6a-40f0-a452-b0f4c89dbdc7","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"%md\nLet's apply the trained model to the test data.","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"85a5a693-3376-4d1a-b9fb-eedbef83a7ff","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":25,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"57628f53-fa07-4b6e-89f0-8534950710b0","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"predictionsDF = savedPipelineModel.transform(testDF)\ndisplay(predictionsDF.select(\"cnt\", \"prediction\"))","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"ffc9ee72-6043-4a6e-91ea-604c45b5bd1e","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":26,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"fd5e7bd3-6aca-497b-b823-7f6994ae9fd8","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"%md\n##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Evaluate\n\nLet's see how well we did on the test set.","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"a4578235-b0b7-4fbf-b53e-16d34d66b60c","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":27,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"9014d9e2-23a7-44d0-b551-aa9333638be5","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"# TODO\nrmse = evaluator.<FILL_IN>\nprint(\"Test RMSE = %f\" % rmse)","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"b34f28e7-fb48-4f9e-a28e-82b0fad82135","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":28,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"c4d46097-2d74-4fa4-945a-e533d5c407f6","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"%md\n#### Improving our model\n\nYou are not done yet!  There are several ways we could further improve our model:\n* **Expert knowledge** \n* **Better tuning** \n* **Feature engineering**\n\nAs an exercise: Replace the Random Forest code with a Gradient Boosted tree, and vary the number of trees and depth of the trees. What do you find?\n\n*Good luck!*","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"522cda96-9553-42c7-8103-6fbf2e030cb4","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":29,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]},{"diffInserts":[],"startTime":0,"state":"finished","subtype":"command","commentThread":[],"guid":"bdb3d68d-bde0-417f-bb60-d9f84a286a88","bindings":{},"displayType":"table","customPlotOptions":{},"collapsed":false,"errorSummary":null,"iPythonMetadata":null,"commandType":"auto","height":"auto","command":"%md-sandbox\n&copy; 2018 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>","pivotColumns":null,"showCommandTitle":false,"pivotAggregation":null,"version":"CommandV1","nuid":"0744d860-7978-4100-8ccb-52d1284d60b3","xColumns":null,"results":null,"commandVersion":0,"hideCommandResult":false,"error":null,"workflows":[],"inputWidgets":{},"finishTime":0,"commandTitle":"","origId":0,"submitTime":0,"position":30,"yColumns":null,"hideCommandCode":false,"latestUser":"","commentsVisible":false,"parentHierarchy":[],"width":"auto","globalVars":{},"diffDeletes":[]}],"globalVars":{}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  