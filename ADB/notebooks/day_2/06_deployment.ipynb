{"cells":[{"cell_type":"markdown","source":["Copyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the MIT License."],"metadata":{}},{"cell_type":"markdown","source":["# Model deployment"],"metadata":{}},{"cell_type":"markdown","source":["Please ensure you have run all previous notebooks in sequence before running this.\n\nPlease Register Azure Container Instance(ACI) using Azure Portal: https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-manager-supported-services#portal in your subscription before using the SDK to deploy your ML model to ACI."],"metadata":{}},{"cell_type":"code","source":["from azureml.core import Workspace\nimport azureml.core\nimport os\n\n# Check core SDK version number\nprint(\"SDK version:\", azureml.core.VERSION)\n\nconfig_path = '/dbfs/tmp/'\n\n#'''\nws = Workspace.from_config(path=os.path.join(config_path, 'aml_config', 'config.json'))\nprint('Workspace name: ' + ws.name, \n      'Azure region: ' + ws.location, \n      'Resource group: ' + ws.resource_group, sep = '\\n')\n#'''"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["## NOTE: service deployment always gets the model from the current working dir.\nmodel_name = \"PdM_logistic_regression.mml\" # \nmodel_name_dbfs = os.path.join(\"/dbfs\", model_name)\n\nprint(\"copy model from dbfs to local\")\nmodel_local = \"file:\" + os.getcwd() + \"/\" + model_name\ndbutils.fs.cp(model_name, model_local, True)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# register the model\nfrom azureml.core.model import Model\nmymodel = Model.register(model_path = model_name, # this points to a local file\n                       model_name = model_name, # this is the name the model is registered as, am using same name for both path and name.                 \n                       description = \"ADB trained model by an amazing data scientist\",\n                       workspace = ws)\n\nprint(mymodel.name, mymodel.description, mymodel.version)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["#%%writefile score_sparkml.py\nscore_sparkml = \"\"\"\n\nimport json\n\ndef init():\n    # One-time initialization of PySpark and predictive model\n    import pyspark\n    from azureml.core.model import Model\n    from pyspark.ml import PipelineModel\n\n    global trainedModel\n    global spark\n\n    spark = pyspark.sql.SparkSession.builder.appName(\"ADB and AML notebook by an amazing data scientist\").getOrCreate()\n    model_name = \"{model_name}\" #interpolated\n    model_path = Model.get_model_path(model_name)\n    trainedModel = PipelineModel.load(model_path)\n    \ndef run(input_json):\n    if isinstance(trainedModel, Exception):\n        return json.dumps({{\"trainedModel\":str(trainedModel)}})\n      \n    try:\n        sc = spark.sparkContext\n        input_list = json.loads(input_json)\n        input_rdd = sc.parallelize(input_list)\n        input_df = spark.read.json(input_rdd)\n    \n        # Compute prediction\n        prediction = trainedModel.transform(input_df)\n        #result = prediction.first().prediction\n        predictions = prediction.collect()\n\n        #Get each scored result\n        preds = [str(x['prediction']) for x in predictions]\n        result = \",\".join(preds)\n        # you can return any data type as long as it is JSON-serializable\n        return json.dumps({{\"result\":result}})        \n    except Exception as e:\n        result = str(e)\n        return json.dumps({{\"error\":result}})\n    \n\"\"\".format(model_name=model_name)\n\nexec(score_sparkml)\n\nwith open(\"score_sparkml.py\", \"w\") as file:\n    file.write(score_sparkml)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["from azureml.core.conda_dependencies import CondaDependencies \n\nmyacienv = CondaDependencies.create(conda_packages=['scikit-learn','numpy','pandas']) #showing how to add libs as an example - not needed for this model.\n\nwith open(\"mydeployenv.yml\",\"w\") as f:\n    f.write(myacienv.serialize_to_string())"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# deploy to ACI\nfrom azureml.core.webservice import AciWebservice, Webservice\n\nmyaci_config = AciWebservice.deploy_configuration(\n    cpu_cores = 2, \n    memory_gb = 2, \n    tags = {'name':'Databricks Azure ML ACI'}, \n    description = 'This is for ADB and AML example. Azure Databricks & Azure ML SDK demo with ACI.')"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# this will take 10-15 minutes to finish\n\nservice_name = \"aciws\"\nruntime = \"spark-py\" \ndriver_file = \"score_sparkml.py\"\nmy_conda_file = \"mydeployenv.yml\"\n\n# image creation\nfrom azureml.core.image import ContainerImage\nmyimage_config = ContainerImage.image_configuration(execution_script = driver_file, \n                                    runtime = runtime, \n                                    conda_file = my_conda_file)\n\n# Webservice creation\nmyservice = Webservice.deploy_from_model(\n  workspace=ws, \n  name=service_name,\n  deployment_config = myaci_config,\n  models = [mymodel],\n  image_config = myimage_config)\n\nmyservice.wait_for_deployment(show_output=True)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["# List images by ws\n\nfor i in ContainerImage.list(workspace = ws):\n    print('{}(v.{} [{}]) stored at {} with build log {}'.format(i.name, i.version, i.creation_state, i.image_location, i.image_build_log_uri))"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["#for using the Web HTTP API \nprint(myservice.scoring_uri)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["%sh\n\nls -la /dbfs/PdM_logistic_regression/*"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["import json\nfrom pyspark.sql.types import *\n\ntest_data_path = \"PdM_logistic_regression\"\ndf_test = spark.read.parquet(test_data_path).limit(5)\ntest_json = json.dumps(df_test.toJSON().collect())\n\nprint(test_json)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["myservice.run(input_data = test_json)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["#comment below line to not delete the web service\nmyservice.delete()"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["Please make sure to install **VS Code** on your compute *before* the next session tmrw morning.\n\nYou can find binary installers for VS Code here:\n\n[https://code.visualstudio.com/download](https://code.visualstudio.com/download)"],"metadata":{}},{"cell_type":"markdown","source":["Copyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the MIT License."],"metadata":{}}],"metadata":{"name":"04.DeploytoACI","notebookId":3771102850754150},"nbformat":4,"nbformat_minor":0}