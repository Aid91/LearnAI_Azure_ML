{"cells":[{"cell_type":"markdown","source":["## Introduction to Model Development with Spark\n\nThis will be the first of three parts of a bootcamp on Model Development with [MLlib](https://spark.apache.org/docs/latest/ml-guide.html), Sparkâ€™s machine learning (ML) library.  You will gain hands-on experience with essential steps of a model development using MLlib, which has has the goal to make machine learning scalable and easy. \n\nAt a high level, MLlib provides tools such as:\n- ML Algorithms: common learning algorithms such as classification, regression, clustering, and collaborative filtering\n- Featurization: feature extraction, transformation, dimensionality reduction, and selection\n- Pipelines: tools for constructing, evaluating, and tuning ML Pipelines\n- Persistence: saving and load algorithms, models, and Pipelines\n- Utilities: linear algebra, statistics, data handling, etc.\n\nIn this lab, we will cover:\n- Splitting of data for training and testing\n- Applying Transformers to data frames\n- Fitting Estimators to our data\n- Creating and executing a ML Pipeline\n- Model Evaluation.\n\nWe will solve a common task in Natural Language Processing (NLP): Sentiment Analysis.  Our dataset from the internet movie database (IMDB) contains roughly 50,000 movie reviews.  Each entry is a movie review written in the English language, as well as the author's rating of the movie on a scale from 1 to 10.  Based on the text of the review, we want to predict if the rating is \"positive\" or \"negative\".\n\nOther applications of Sentiment Analysis:\n- Detecting negative affect in customers who are calling an automated customer hotline\n- Agreggating reviews of retail products into an overall rating for each product"],"metadata":{}},{"cell_type":"markdown","source":["## Initialize Environment\n\nAs usual we start by setting up our environment and mounting our data."],"metadata":{}},{"cell_type":"code","source":["%run \"../includes/mnt_blob\""],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["%run \"../includes/setup_env\""],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["reviewsDF = spark.read.parquet(\"/mnt/data/imdb/imdb_ratings_50k.parquet\")\nreviewsDF.createOrReplaceTempView(\"reviews\")\ndisplay(reviewsDF)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["What does the distribution of scores look like?\n\nHINT: Use `count()`"],"metadata":{}},{"cell_type":"code","source":["%sql\n--TODO: Replace <FILL IN> with appropriate code\n\nSELECT <FILL_IN>"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["The authors of this dataset have removed the \"neutral\" ratings, which they defined as a rating of 5 or 6."],"metadata":{}},{"cell_type":"markdown","source":["## Train-Test Split\n\nWe'll split our data into training and test samples. We will use 80% for training, and the remaining 20% for testing. We set a seed to reproduce the same results (i.e. if you re-run this notebook, you'll get the same results both times)."],"metadata":{}},{"cell_type":"code","source":["(trainDF, testDF) = reviewsDF.randomSplit([0.8, 0.2], seed=42)\ntrainDF.cache()\ntestDF.cache()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["Let's determine our baseline accuracy."],"metadata":{}},{"cell_type":"code","source":["positiveRatings = trainDF.filter(\"rating >= 5\").count()\ntotalRatings = trainDF.count()\n\nprint(\"Baseline accuracy: {0:.2f}%\".format(positiveRatings/totalRatings*100))"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["## Transformers\n\nA transformer takes in a DataFrame, and returns a new DataFrame with one or more columns appended to it. They implement a `.transform()` method."],"metadata":{}},{"cell_type":"markdown","source":["Let's get started by using [RegexTokenizer](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.RegexTokenizer) to convert our review string into a list of tokens."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import RegexTokenizer\n\ntokenizer = (RegexTokenizer()\n            .setInputCol(\"review\")\n            .setOutputCol(\"tokens\")\n            .setPattern(\"\\\\W+\"))\n\ntokenizedDF = tokenizer.transform(reviewsDF)\ndisplay(tokenizedDF.limit(5)) # Look at a few tokenized reviews"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["There are a lot of words that do not contain much information about the sentiment of the review (e.g. `the`, `a`, etc.). Let's remove these uninformative words using [StopWordsRemover](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.StopWordsRemover)."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import StopWordsRemover\n\nremover = (StopWordsRemover()\n          .setInputCol(\"tokens\")\n          .setOutputCol(\"stopWordFree\"))\n\nremovedStopWordsDF = remover.transform(tokenizedDF)\ndisplay(removedStopWordsDF.limit(5)) # Look at a few tokenized reviews without stop words"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["Where do the stop words actually come from? Spark includes a small English list as a default, which we're implicitly using here."],"metadata":{}},{"cell_type":"code","source":["stopWords = remover.getStopWords()\nstopWords"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["Let's remove the `br` from our reviews."],"metadata":{}},{"cell_type":"code","source":["remover.setStopWords([\"br\"] + stopWords)\nremovedStopWordsDF = remover.transform(tokenizedDF)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["## Estimators\n\nEstimators take in a DataFrame, and return a model (a Transformer). They implement a `.fit()` method."],"metadata":{}},{"cell_type":"markdown","source":["Let's apply a [CountVectorizer](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.CountVectorizer) model to convert our tokens into a vocabulary."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import CountVectorizer\n\ncounts = (CountVectorizer()\n          .setInputCol(\"stopWordFree\")\n          .setOutputCol(\"features\")\n          .setVocabSize(1000))\n\ncountModel = counts.fit(removedStopWordsDF) # It's a model"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["__Now let's adjust the label (target) values__\n\nWe want to group the reviews into \"positive\" or \"negative\" sentiment. So all of the star \"levels\" need to be collapsed into one of two groups. To accomplish this, we will use [Binarizer](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.Binarizer)."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import Binarizer\n\nbinarizer = (Binarizer()\n            .setInputCol(\"rating\")\n            .setOutputCol(\"label\")\n            .setThreshold(5.0))"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["Now we are going to use a Decision Tree model to fit to our dataset."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import DecisionTreeClassifier\n\ndtc = DecisionTreeClassifier()"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":["## Pipeline\n\nLet's put all of these stages into a [Pipeline](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.Pipeline). This way, you don't have to remember all of the different steps you applied to the training set, and then apply the same steps to the test dataset. The pipeline takes care of that for you!"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\n\npipeline = Pipeline().setStages([tokenizer, remover, counts, binarizer, dtc])\npipelineModel = pipeline.fit(trainDF)"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":["We can extract the stages from our Pipeline, such as the Decision Tree model."],"metadata":{}},{"cell_type":"code","source":["decisionTree = pipelineModel.stages[-1]\nprint(decisionTree.toDebugString)"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":["Let's save the pipeline model."],"metadata":{}},{"cell_type":"code","source":["fileName = userhome + \"/tmp/DT_Pipeline\"\npipelineModel.write().overwrite().save(fileName)"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":["Now let's load the `PipelineModel` back in.\n\n**Note**: You need to know what type of model you're loading in."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml import PipelineModel\n# Load saved model\nsavedPipelineModel = PipelineModel.load(fileName)"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["resultDF = savedPipelineModel.transform(testDF)"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":["## Evaluate\n\nWe are going to use [MultiClassClassificationEvaluator](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator)  to evaluate our predictions (we are using MultiClass because the BinaryClassificationEvaluator does not support accuracy as a metric)."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nevaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\nprint(\"Accuracy: %(result)s\" % {\"result\": evaluator.evaluate(resultDF)})"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":["#### Confusion Matrix\n\nLet's see if we had more False Positive or False Negatives."],"metadata":{}},{"cell_type":"code","source":["display(resultDF.groupBy(\"label\", \"prediction\").count())"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":["Later, we will see how to apply this pipeline to streaming data!"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2018 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"04a_sparkML_demo","notebookId":3771102850753825},"nbformat":4,"nbformat_minor":0}
