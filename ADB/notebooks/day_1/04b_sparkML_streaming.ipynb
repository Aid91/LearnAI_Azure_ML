{"cells":[{"cell_type":"markdown","source":["## SparkML on Streaming Data"],"metadata":{}},{"cell_type":"markdown","source":["Let's take in the model we saved earlier, and apply it to some streaming data!"],"metadata":{}},{"cell_type":"code","source":["%run \"../includes/mnt_blob\""],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["%run \"../includes/setup_env\""],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["from pyspark.ml.pipeline import PipelineModel\n\nfileName = userhome + \"/tmp/DT_Pipeline\"\npipelineModel = PipelineModel.load(fileName)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["We can simulate streaming data.\n\nNOTE: You must specify a schema when creating a streaming source DataFrame."],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.types import *\n\nschema = StructType([\n  StructField(\"rating\",DoubleType()), \n  StructField(\"review\",StringType())])\n\nstreamingData = (spark\n                 .readStream\n                 .schema(schema)\n                 .option(\"maxFilesPerTrigger\", 1)\n                 .parquet(\"/mnt/data/imdb/imdb_ratings_50k.parquet\"))"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["Why is this stream taking so long? What configuration should we set?"],"metadata":{}},{"cell_type":"code","source":["stream = (pipelineModel\n          .transform(streamingData)\n          .groupBy(\"label\", \"prediction\")\n          .count()\n          .sort(\"label\", \"prediction\"))\n\ndisplay(stream)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["spark.conf.get(\"spark.sql.shuffle.partitions\")"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.shuffle.partitions\", \"8\")"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["Let's try this again"],"metadata":{}},{"cell_type":"code","source":["stream = (pipelineModel\n          .transform(streamingData)\n          .groupBy(\"label\", \"prediction\")\n          .count()\n          .sort(\"label\", \"prediction\"))\n\ndisplay(stream)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["Let's save our results to a file."],"metadata":{}},{"cell_type":"code","source":["import re\n\nstreamingView = re.sub('\\W', '', username)\ncheckpointFile = userhome + \"/tmp/checkPoint\"\ndbutils.fs.rm(checkpointFile, True) # Clear out the checkpointing directory\n\n(stream\n .writeStream\n .format(\"memory\")\n .option(\"checkpointLocation\", checkpointFile)\n .outputMode(\"complete\")\n .queryName(streamingView)\n .start())"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["display(sql(\"select * from \" + streamingView))"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["-sandbox\n&copy; 2018 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"04b_sparkML_streaming","notebookId":3771102850753969},"nbformat":4,"nbformat_minor":0}
